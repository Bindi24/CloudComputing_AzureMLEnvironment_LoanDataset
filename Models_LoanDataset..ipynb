{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was generated from the following AutoML run:\n",
        "\n",
        "https://ml.azure.com/runs/model_loan_validationset_21?wsid=/subscriptions/84677e42-3672-4e5b-98f7-81f8a44649a9/resourcegroups/ML_Project/workspaces/ML_ProjectWS1"
      ],
      "metadata": {
        "automl_codegen": {
          "arguments": [
            "automl_child_run_id",
            "child_run_url"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (A) Automated ML Method - Voting Ensemble Model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Train using Azure Machine Learning Compute\n",
        "\n",
        "* Connect to an Azure Machine Learning Workspace\n",
        "* Use existing compute target or create new\n",
        "* Configure & Run command\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "Please ensure Azure Machine Learning Python SDK v2 is installed on the machine running Jupyter."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to a Workspace\n",
        "\n",
        "Initialize a workspace object from the previous experiment. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# The workspace information from the previous experiment has been pre-filled for you.\n",
        "subscription_id = \"84677e42-3672-4e5b-98f7-81f8a44649a9\"\n",
        "resource_group = \"ML_Project\"\n",
        "workspace_name = \"ML_ProjectWS1\"\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)\n",
        "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
        "print(ml_client.workspace_name, workspace.resource_group, workspace.location, ml_client.connections._subscription_id, sep = '\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "create workspace"
        ],
        "automl_codegen": {
          "arguments": [
            "subscription_id",
            "resource_group",
            "workspace_name"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create project directory\n",
        "\n",
        "Create a directory that will contain the training script that you will need access to on the remote resource."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "project_folder = os.path.join(\".\", 'code_folder')\n",
        "os.makedirs(project_folder, exist_ok=True)\n",
        "shutil.copy('script.py', project_folder)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use existing compute target or create new (Basic)\n",
        "\n",
        "Azure Machine Learning Compute is managed compute infrastructure that allows the user to easily create single to multi-node compute of the appropriate VM Family. It is created **within your workspace region** and is a resource that can be used by other users in your workspace. It autoscales by default to the max_nodes, when a job is submitted, and executes in a containerized environment packaging the dependencies as specified by the user. \n",
        "\n",
        "Since it is managed compute, job scheduling and cluster management are handled internally by Azure Machine Learning service. \n",
        "\n",
        "A compute cluster can be created using the `AmlCompute` class. Some of the key parameters of this class are:\n",
        "\n",
        "* `size` - The VM size to use for the cluster. For more information, see [Supported VM series and sizes](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes).\n",
        "* `max_instances` - The maximum number of nodes to use on the cluster. Default is 1."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cluster_name = \"cpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cluster = ml_client.compute.get(cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except Exception:\n",
        "    compute = AmlCompute(name=cluster_name, size='STANDARD_D2_V2',\n",
        "                         max_instances=4)\n",
        "    cluster = ml_client.compute.begin_create_or_update(compute)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "sample-amlcompute-provision"
        ],
        "automl_codegen": {
          "arguments": [
            "compute_target",
            "compute_sku"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure & Run\n",
        "The environment and compute has been pre-filled from the original training job. More information can be found here:\n",
        "\n",
        "`command`: https://docs.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml?view=azure-python-preview#azure-ai-ml-command\n",
        "\n",
        "`environment`: https://docs.microsoft.com/en-us/azure/machine-learning/resource-curated-environments#automated-ml-automl\n",
        "\n",
        "`compute`: https://docs.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.amlcompute?view=azure-python-preview\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# To test the script with an environment referenced by a custom yaml file, uncomment the following lines and replace the `conda_file` value with the path to the yaml file.\n",
        "# Set the value of `environment` in the `command` job below to `env`.\n",
        "\n",
        "# env = Environment(\n",
        "#    name=\"automl-tabular-env\",\n",
        "#    description=\"environment for automl inference\",\n",
        "#    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20210727.v1\",\n",
        "#    conda_file=\"conda.yaml\",\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, Input\n",
        "\n",
        "# To test with new training / validation datasets, replace the default dataset id(s)/uri(s) taken from parent run below\n",
        "command_str = 'python script.py --training_dataset_uri azureml://locations/eastus/workspaces/7171f9b6-3d02-48f4-ac3a-50cd60c22aea/data/Loan_dataset/versions/1'\n",
        "command_job = command(\n",
        "    code=project_folder,\n",
        "    command=command_str,\n",
        "    tags=dict(automl_child_run_id='model_loan_validationset_21'),\n",
        "    environment='AzureML-AutoML:172',\n",
        "    compute='cpu-cluster',\n",
        "    experiment_name='Model_Loan_Validationset')\n",
        " \n",
        "returned_job = ml_client.create_or_update(command_job)\n",
        "returned_job.studio_url"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "automl_codegen": {
          "arguments": [
            "script_filename",
            "script_arguments",
            "environment_name",
            "environment_version",
            "compute_target",
            "experiment_name",
            "automl_child_run_id"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize MLFlow Client\n",
        "The metrics and artifacts for the run can be accessed via the MLFlow interface. \n",
        "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
        "\n",
        "*IMPORTANT*, you need to have installed the latest MLFlow packages with:\n",
        "\n",
        "    pip install azureml-mlflow\n",
        "\n",
        "    pip install mlflow"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install azureml-mlflow\n",
        "# %pip install mlflow"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "# Obtain the tracking URL from MLClient\n",
        "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
        "    name=ml_client.workspace_name\n",
        ").mlflow_tracking_uri\n",
        "\n",
        "# Set the MLFLOW TRACKING URI\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "\n",
        "# Retrieve the metrics logged to the run.\n",
        "from mlflow.tracking.client import MlflowClient\n",
        "\n",
        "# Initialize MLFlow client\n",
        "mlflow_client = MlflowClient()\n",
        "mlflow_run = mlflow_client.get_run(returned_job.name)\n",
        "mlflow_run.data.metrics\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Fitted Model\n",
        "Download the resulting fitted model to the local folder in `local_dir`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# Create local folder\n",
        "# local_dir = \"./artifact_downloads\"\n",
        "# if not os.path.exists(local_dir):\n",
        "#     os.mkdir(local_dir)\n",
        "# Download run's artifacts/outputs\n",
        "# local_path = mlflow_client.download_artifacts(\n",
        "#     mlflow_run.info.run_id, \"outputs\", local_dir# )\n",
        "# print(\"Artifacts downloaded in: {}\".format(local_path))\n",
        "# print(\"Artifacts: {}\".format(os.listdir(local_path)))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Code after Deployment "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "data =  {\n",
        "  \"input_data\": {\n",
        "    \"columns\": [\n",
        "      \"no_of_dependents\",\n",
        "      \"education\",\n",
        "      \"self_employed\",\n",
        "      \"income_annum\",\n",
        "      \"loan_amount\",\n",
        "      \"loan_term\",\n",
        "      \"cibil_score\",\n",
        "      \"residential_assets_value\",\n",
        "      \"commercial_assets_value\",\n",
        "      \"luxury_assets_value\",\n",
        "      \"bank_asset_value\"\n",
        "    ],\n",
        "    \"index\": [],\n",
        "    \"data\": []\n",
        "  }\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "url = 'https://ml-projectws1-group1-loan.eastus.inference.ml.azure.com/score'\n",
        "# Replace this with the primary/secondary key, AMLToken, or Microsoft Entra ID token for the endpoint\n",
        "api_key = ''\n",
        "if not api_key:\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'ml-projectws1-group1-loan' }\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (B)Pipeline Method - Boosted Decision Tree Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import traceback\n",
        "\n",
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "try:\n",
        "    from azureml.train.automl._remote_script import model_test_wrapper\n",
        "    print(\"SDK supports model testing.\")\n",
        "except Exception:\n",
        "    print(\"SDK does not support model testing.\")\n",
        "    raise\n",
        "\n",
        "\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "try:\n",
        "    from azureml.train.automl._remote_script import setup_wrapper\n",
        "    from azureml.train.automl._remote_script import driver_wrapper\n",
        "except Exception as e:\n",
        "    print(\"v2 driver import failed with exception: {}. Falling back to v1 driver.\".format(e))\n",
        "    traceback.print_exc()\n",
        "    import importlib\n",
        "    import inspect\n",
        "    import logging\n",
        "    import os\n",
        "    import sys\n",
        "    import time\n",
        "\n",
        "    from automl.client.core.common import utilities\n",
        "    from azureml.core.experiment import Experiment\n",
        "    from azureml.core.run import Run\n",
        "    from azureml.train.automl import automl\n",
        "    from azureml.train.automl import fit_pipeline\n",
        "    from azureml.train.automl._automl_settings import _AutoMLSettings\n",
        "\n",
        "    try:\n",
        "        from azureml.train.automl._cachestore import _CacheStore\n",
        "        from azureml.train.automl._preprocessorcontexts import (RawDataContext,\n",
        "                                                            TransformedDataContext)\n",
        "        from azureml.train.automl._transform_data import _transform_data\n",
        "        sdk_has_cache_capability = True\n",
        "    except ImportError:\n",
        "        sdk_has_cache_capability = False\n",
        "\n",
        "    try:\n",
        "        from azureml.train.automl.utilities import _validate_data_splits\n",
        "        sdk_has_validate_data_splits = True\n",
        "    except ImportError:\n",
        "        sdk_has_validate_data_splits = False\n",
        "\n",
        "    try:\n",
        "        # Works only for azureml-train-automl>1.0.10\n",
        "        from automl.client.core.common.training_utilities import validate_training_data, check_x_y\n",
        "    except:\n",
        "        from azureml.train.automl.utilities import _validate_training_data as validate_training_data, _check_x_y as check_x_y\n",
        "\n",
        "    try:\n",
        "        from automl.client.core.common.training_utilities import validate_training_data_dict\n",
        "        sdk_has_validate_data_dict = True\n",
        "    except:\n",
        "        sdk_has_validate_data_dict = False\n",
        "\n",
        "\n",
        "    try:\n",
        "        from automl.client.core.common.logging_utilities import log_traceback\n",
        "    except ImportError:\n",
        "        def log_traceback(exception, logger, **kwargs):\n",
        "            \"\"\"Do nothing if not imported.\"\"\"\n",
        "            pass\n",
        "\n",
        "    # holding these strings here to identify the exception that created by this script\n",
        "    try:\n",
        "        from  automl.client.core.common.exceptions import ErrorTypes\n",
        "    except ImportError:\n",
        "        class ErrorTypes:\n",
        "            \"\"\"Possible types of errors.\"\"\"\n",
        "\n",
        "            User = 'User'\n",
        "            Service = 'Service'\n",
        "            Client = 'Client'\n",
        "            Unclassified = 'Unclassified'\n",
        "            All = {User, Service, Client, Unclassified}\n",
        "\n",
        "    def _get_auto_cv(X, y, X_valid, y_valid, cv_splits_indices, automl_settings_obj, logger):\n",
        "        if hasattr(automl_settings_obj, \"rule_based_validation\"):\n",
        "            return automl_settings_obj.rule_based_validation(\n",
        "                X, y, X_valid, y_valid, cv_splits_indices,\n",
        "                logger=logger)\n",
        "        else:\n",
        "            logger.info(\"SDK has no auto cv capability.\")\n",
        "            return X, y, X_valid, y_valid\n",
        "\n",
        "    def _get_auto_cv_dict(input_dict, automl_settings_obj, logger):\n",
        "        input_dict['X'], input_dict['y'], input_dict['X_valid'], input_dict['y_valid'] = _get_auto_cv(\n",
        "            input_dict.get('X'),\n",
        "            input_dict.get('y'),\n",
        "            input_dict.get('X_valid'),\n",
        "            input_dict.get('y_valid'),\n",
        "            input_dict.get('cv_splits_indices'),\n",
        "            automl_settings_obj,\n",
        "            logger=logger)\n",
        "        return input_dict\n",
        "\n",
        "    def _get_cv_from_transformed_data_context(transformed_data_context, logger):\n",
        "        n_cv = None\n",
        "        if transformed_data_context._on_demand_pickle_keys is None:\n",
        "            n_cv = None\n",
        "        else:\n",
        "            n_cv = sum([1 if \"cv\" in key else 0 for key in transformed_data_context._on_demand_pickle_keys])\n",
        "        logger.info(\"The cv got from transformed_data_context is {}.\".format(n_cv))\n",
        "        return n_cv\n",
        "\n",
        "    def _get_data_from_dataprep(dataprep_json, automl_settings_obj, logger):\n",
        "        current_run = Run.get_submitted_run()\n",
        "        parent_run_id = _get_parent_run_id(current_run._run_id)\n",
        "        print(\"[ParentRunId:{}]: Start getting data using dataprep.\".format(parent_run_id))\n",
        "        logger.info(\"[ParentRunId:{}]: Start getting data using dataprep.\".format(parent_run_id))\n",
        "        try:\n",
        "            import azureml.train.automl._dataprep_utilities as dataprep_utilities\n",
        "        except Exception as e:\n",
        "            e.error_type = ErrorTypes.Unclassified\n",
        "            log_traceback(e, logger)\n",
        "            logger.error(e)\n",
        "            raise e\n",
        "\n",
        "        fit_iteration_parameters_dict = dict()\n",
        "\n",
        "        class RetrieveNumpyArrayError(Exception):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "\n",
        "        try:\n",
        "            print(\"Resolving Dataflows...\")\n",
        "            logger.info(\"Resolving Dataflows...\")\n",
        "            dataprep_json_obj = json.loads(dataprep_json)\n",
        "            if 'activities' in dataprep_json_obj: # json is serialized dataflows\n",
        "                dataflow_dict = dataprep_utilities.load_dataflows_from_json(\n",
        "                    dataprep_json)\n",
        "                for k in ['X', 'X_valid', 'sample_weight', 'sample_weight_valid']:\n",
        "                    fit_iteration_parameters_dict[k] = dataprep_utilities.try_retrieve_pandas_dataframe(dataflow_dict.get(k))\n",
        "                for k in ['y', 'y_valid']:\n",
        "                    try:\n",
        "                        fit_iteration_parameters_dict[k] = dataprep_utilities.try_retrieve_numpy_array(dataflow_dict.get(k))\n",
        "                    except IndexError:\n",
        "                        raise RetrieveNumpyArrayError()\n",
        "\n",
        "                cv_splits_dataflows = []\n",
        "                i = 0\n",
        "                while 'cv_splits_indices_{0}'.format(i) in dataflow_dict:\n",
        "                    cv_splits_dataflows.append(\n",
        "                        dataflow_dict['cv_splits_indices_{0}'.format(i)])\n",
        "                    i = i + 1\n",
        "                fit_iteration_parameters_dict['cv_splits_indices'] = None if len(cv_splits_dataflows) == 0 \\\n",
        "                    else dataprep_utilities.try_resolve_cv_splits_indices(cv_splits_dataflows)\n",
        "            else: # json is dataprep options\n",
        "                print('Creating Dataflow from options...\\r\\nOptions:')\n",
        "                logger.info('Creating Dataflow from options...')\n",
        "                print(dataprep_json_obj)\n",
        "                datastore_name = dataprep_json_obj['datastoreName'] # mandatory\n",
        "                data_path = dataprep_json_obj['dataPath'] # mandatory\n",
        "                label_column = dataprep_json_obj['label'] # mandatory\n",
        "                separator = dataprep_json_obj.get('columnSeparator', ',')\n",
        "                header = dataprep_json_obj.get('promoteHeader', True)\n",
        "                encoding = dataprep_json_obj.get('encoding', None)\n",
        "                quoting = dataprep_json_obj.get('ignoreNewlineInQuotes', False)\n",
        "                skip_rows = dataprep_json_obj.get('skipRows', 0)\n",
        "                feature_columns = dataprep_json_obj.get('features', [])\n",
        "\n",
        "                from azureml.core import Datastore\n",
        "                import azureml.dataprep as dprep\n",
        "                if header:\n",
        "                    header = dprep.PromoteHeadersMode.CONSTANTGROUPED\n",
        "                else:\n",
        "                    header = dprep.PromoteHeadersMode.NONE\n",
        "                try:\n",
        "                    encoding = dprep.FileEncoding[encoding]\n",
        "                except:\n",
        "                    encoding = dprep.FileEncoding.UTF8\n",
        "\n",
        "                ws = Run.get_context().experiment.workspace\n",
        "                datastore = Datastore(ws, datastore_name)\n",
        "                dflow = dprep.read_csv(path=datastore.path(data_path),\n",
        "                                        separator=separator,\n",
        "                                        header=header,\n",
        "                                        encoding=encoding,\n",
        "                                        quoting=quoting,\n",
        "                                        skip_rows=skip_rows)\n",
        "\n",
        "                if len(feature_columns) == 0:\n",
        "                    X = dflow.drop_columns(label_column)\n",
        "                else:\n",
        "                    X = dflow.keep_columns(feature_columns)\n",
        "\n",
        "                print('Inferring types for feature columns...')\n",
        "                logger.info('Inferring types for feature columns...')\n",
        "                sct = X.builders.set_column_types()\n",
        "                sct.learn()\n",
        "                sct.ambiguous_date_conversions_drop()\n",
        "                X = sct.to_dataflow()\n",
        "\n",
        "                y = dflow.keep_columns(label_column)\n",
        "                if automl_settings_obj.task_type.lower() == 'regression':\n",
        "                    y = y.to_number(label_column)\n",
        "\n",
        "                print('X:')\n",
        "                print(X)\n",
        "                logger.info('X:')\n",
        "                logger.info(X)\n",
        "\n",
        "                print('y:')\n",
        "                print(y)\n",
        "                logger.info('y:')\n",
        "                logger.info(y)\n",
        "\n",
        "                try:\n",
        "                    from azureml.train.automl._dataprep_utilities import try_retrieve_pandas_dataframe_adb\n",
        "                    _X = try_retrieve_pandas_dataframe_adb(X)\n",
        "                    fit_iteration_parameters_dict['X'] = _X.values\n",
        "                    fit_iteration_parameters_dict['x_raw_column_names'] = _X.columns.values\n",
        "                except ImportError:\n",
        "                    logger.info(\"SDK version does not support column names extraction, fallback to old path\")\n",
        "                    fit_iteration_parameters_dict['X'] = dataprep_utilities.try_retrieve_pandas_dataframe(X)\n",
        "\n",
        "                try:\n",
        "                    fit_iteration_parameters_dict['y'] = dataprep_utilities.try_retrieve_numpy_array(y)\n",
        "                except IndexError:\n",
        "                    raise RetrieveNumpyArrayError()\n",
        "\n",
        "            logger.info(\"Finish getting data using dataprep.\")\n",
        "            return fit_iteration_parameters_dict\n",
        "        except Exception as e:\n",
        "            print(\"[ParentRunId:{0}]: Error from resolving Dataflows: {1} {2}\".format(parent_run_id, e.__class__, e))\n",
        "            logger.error(\"[ParentRunId:{0}]: Error from resolving Dataflows: {1} {2}\".format(parent_run_id, e.__class__, e))\n",
        "            if isinstance(e, RetrieveNumpyArrayError):\n",
        "                logger.debug(\"Label column (y) does not exist in user's data.\")\n",
        "                e.error_type = ErrorTypes.User\n",
        "            elif \"The provided path is not valid.\" in str(e):\n",
        "                logger.debug(\"User's data is not accessible from remote run.\")\n",
        "                e.error_type = ErrorTypes.User\n",
        "            elif \"Required secrets are missing. Please call use_secrets to register the missing secrets.\" in str(e):\n",
        "                logger.debug(\"User should use Datastore to data that requires secrets.\")\n",
        "                e.error_type = ErrorTypes.User\n",
        "            else:\n",
        "                e.error_type = ErrorTypes.Client\n",
        "            log_traceback(e, logger)\n",
        "            raise RuntimeError(\"Error during extracting Dataflows\")\n",
        "\n",
        "    def _init_logger(automl_settings_obj=None):\n",
        "        sdk_has_custom_dimension_logger = False\n",
        "        try:\n",
        "            from azureml.telemetry import set_diagnostics_collection\n",
        "            if automl_settings_obj is not None:\n",
        "                set_diagnostics_collection(send_diagnostics=automl_settings_obj.send_telemetry,\n",
        "                                           verbosity=automl_settings_obj.telemetry_verbosity)\n",
        "        except:\n",
        "            print(\"set_diagnostics_collection failed.\")\n",
        "\n",
        "        try:\n",
        "            from azureml.train.automl._logging import get_logger\n",
        "            if \"automl_settings\" in inspect.getcallargs(get_logger, log_file_name=\"AutoML_remote.log\"):\n",
        "                logger = get_logger(log_file_name=\"AutoML_remote.log\", automl_settings=automl_settings_obj)\n",
        "                sdk_has_custom_dimension_logger = True\n",
        "            else:\n",
        "                logger = get_logger(log_file_name=\"AutoML_remote.log\")\n",
        "                sdk_has_custom_dimension_logger = False\n",
        "            logger.info(\"sdk_has_custom_dimension_logger {}.\".format(sdk_has_custom_dimension_logger))\n",
        "        except ImportError:\n",
        "            logger = logging.getLogger(__name__)\n",
        "            logger.addHandler(logging.NullHandler())\n",
        "        logger.info(\"Init logger successfully with automl_settings {}.\".format(automl_settings_obj))\n",
        "        try:\n",
        "            from automl.client.core.common.utilities import get_sdk_dependencies\n",
        "            logger.info(get_sdk_dependencies())\n",
        "        except Exception as e:\n",
        "            pass\n",
        "        return logger, sdk_has_custom_dimension_logger\n",
        "\n",
        "    def _init_directory(directory, logger):\n",
        "        logger.info(\"Start init directory.\")\n",
        "        if(directory == None):\n",
        "            directory = os.path.dirname(__file__)\n",
        "\n",
        "        logger.info(\"Adding directory to system path.\")\n",
        "        sys.path.append(directory)\n",
        "\n",
        "        # create the outputs folder\n",
        "        logger.info(\"Creating output folder.\")\n",
        "        os.makedirs('./outputs', exist_ok=True)\n",
        "        print(\"create output folder\")\n",
        "        logger.info(\"Finished init directory.\")\n",
        "        return directory\n",
        "\n",
        "    def _get_parent_run_id(run_id):\n",
        "        split = run_id.split(\"_\")\n",
        "        if len(split) > 2:\n",
        "            split.pop()\n",
        "        else:\n",
        "            return run_id\n",
        "\n",
        "        parent_run_id = '_'.join(str(e) for e in split)\n",
        "        return parent_run_id\n",
        "\n",
        "    def _load_data_from_user_script(script_directory, entry_point, logger):\n",
        "        #  Load user script to get access to GetData function\n",
        "        logger.info(\"Loading data using user script.\")\n",
        "        try:\n",
        "            from azureml.train.automl import extract_user_data\n",
        "        except Exception as e:\n",
        "            logger.warning(e)\n",
        "\n",
        "        module_name = None\n",
        "        if (entry_point.endswith('.py')):\n",
        "            module_name = entry_point[:-3]\n",
        "\n",
        "        spec = importlib.util.spec_from_file_location(\n",
        "            module_name, os.path.join(script_directory, entry_point))\n",
        "        module_obj = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(module_obj)\n",
        "        # print(\"Extracting user Data from {0}\".format(module_name))\n",
        "\n",
        "        fit_iteration_parameters_dict = dict()\n",
        "        try:\n",
        "            output_dict = extract_user_data(module_obj)\n",
        "            for k, v in output_dict.items():\n",
        "                fit_iteration_parameters_dict[k] = v\n",
        "        except Exception as e:\n",
        "            logger.warning(\"Meeting exceptions using user script {}.\".format(e))\n",
        "            fit_iteration_parameters_dict['X'], fit_iteration_parameters_dict['y'] = module_obj.get_data()\n",
        "\n",
        "        return fit_iteration_parameters_dict\n",
        "\n",
        "    def _prepare_data(dataprep_json, automl_settings_obj, script_directory, entry_point, logger):\n",
        "        if dataprep_json:\n",
        "            return _get_data_from_dataprep(dataprep_json, automl_settings_obj, logger)\n",
        "        else:\n",
        "            return _load_data_from_user_script(script_directory, entry_point, logger)\n",
        "\n",
        "    def _get_transformed_data_context(X, y, X_valid, y_valid,\n",
        "                                     sample_weight, sample_weight_valid,\n",
        "                                     x_raw_column_names, cv_splits_indices,\n",
        "                                     data_store, run_target,\n",
        "                                     automl_settings_obj, parent_run_id, logger,\n",
        "                                     raw_data_context=None):\n",
        "        logger.info(\"Getting transformed data context.\")\n",
        "        if raw_data_context is None:\n",
        "            logger.info(\"raw_data_context is None, creating a new one.\")\n",
        "            raw_data_context = RawDataContext(task_type=automl_settings_obj.task_type,\n",
        "                                              X=X,\n",
        "                                              y=y,\n",
        "                                              X_valid=X_valid,\n",
        "                                              y_valid=y_valid,\n",
        "                                              sample_weight=sample_weight,\n",
        "                                              sample_weight_valid=sample_weight_valid,\n",
        "                                              x_raw_column_names=x_raw_column_names,\n",
        "                                              lag_length=automl_settings_obj.lag_length,\n",
        "                                              cv_splits_indices=cv_splits_indices,\n",
        "                                              automl_settings_obj=automl_settings_obj,\n",
        "                                              enable_cache=automl_settings_obj.enable_cache,\n",
        "                                              data_store=data_store,\n",
        "                                              run_target='remote',\n",
        "                                              timeseries=automl_settings_obj.is_timeseries,\n",
        "                                              timeseries_param_dict=utilities._get_ts_params_dict(automl_settings_obj)\n",
        "                                              )\n",
        "\n",
        "        transformed_data_context = _transform_data(raw_data_context=raw_data_context,\n",
        "                                                   preprocess=automl_settings_obj.preprocess,\n",
        "                                                   logger=logger,\n",
        "                                                   run_id=parent_run_id)\n",
        "        logger.info(\"Finished getting transformed data context.\")\n",
        "\n",
        "        return transformed_data_context\n",
        "\n",
        "    def _set_problem_info_for_setup(fit_iteration_parameters_dict,\n",
        "                                   automl_settings_obj, task_type, preprocess,\n",
        "                                   enable_subsampling, num_iterations,\n",
        "                                   logger):\n",
        "        current_run = Run.get_submitted_run()\n",
        "        logger.info(\"Start to set problem info for the setup for run id {}.\".format(current_run._run_id))\n",
        "        logger.info(\"Setup experiment.\")\n",
        "        try:\n",
        "            experiment = current_run.experiment\n",
        "            parent_run_id = _get_parent_run_id(current_run._run_id)\n",
        "            data_store = experiment.workspace.get_default_datastore()\n",
        "            found_data_store = True\n",
        "            logger.info(\"Using data store.\")\n",
        "        except Exception as e:\n",
        "            logger.warning(\"Getting data store, fallback to default {}\".format(e))\n",
        "            found_data_store = False\n",
        "\n",
        "        logger.info(\"Caching supported {}.\".format(sdk_has_cache_capability and found_data_store))\n",
        "        print(\"caching supported {}\".format(sdk_has_cache_capability and found_data_store))\n",
        "        if sdk_has_validate_data_dict:\n",
        "            # The newest version of validate_training_data_dict should contains check_x_y\n",
        "            logger.info(\"Using validate_training_data_dict now.\")\n",
        "            validate_training_data_dict(data_dict=fit_iteration_parameters_dict, automl_settings=automl_settings_obj)\n",
        "        else:\n",
        "            logger.info(\"Using validate_training_data now.\")\n",
        "            validate_training_data(X=fit_iteration_parameters_dict.get('X'),\n",
        "                                      y=fit_iteration_parameters_dict.get('y'),\n",
        "                                      X_valid=fit_iteration_parameters_dict.get('X_valid'),\n",
        "                                      y_valid=fit_iteration_parameters_dict.get('y_valid'),\n",
        "                                      sample_weight=fit_iteration_parameters_dict.get('sample_weight'),\n",
        "                                      sample_weight_valid=fit_iteration_parameters_dict.get('sample_weight_valid'),\n",
        "                                      cv_splits_indices=fit_iteration_parameters_dict.get('cv_splits_indices'),\n",
        "                                      automl_settings=automl_settings_obj)\n",
        "            check_x_y(fit_iteration_parameters_dict.get('X'), fit_iteration_parameters_dict.get('y'), automl_settings_obj)\n",
        "        if sdk_has_cache_capability and found_data_store:\n",
        "            data_splits_validated = True\n",
        "            try:\n",
        "                start = time.time()\n",
        "                transformed_data_context = _get_transformed_data_context(\n",
        "                    X=fit_iteration_parameters_dict.get('X'),\n",
        "                    y=fit_iteration_parameters_dict.get('y'),\n",
        "                    X_valid=fit_iteration_parameters_dict.get('X_valid'),\n",
        "                    y_valid=fit_iteration_parameters_dict.get('y_valid'),\n",
        "                    sample_weight=fit_iteration_parameters_dict.get('sample_weight'),\n",
        "                    sample_weight_valid=fit_iteration_parameters_dict.get('sample_weight_valid'),\n",
        "                    x_raw_column_names=fit_iteration_parameters_dict.get('x_raw_column_names'),\n",
        "                    cv_splits_indices=fit_iteration_parameters_dict.get('cv_splits_indices'),\n",
        "                    automl_settings_obj=automl_settings_obj,\n",
        "                    data_store=data_store,\n",
        "                    run_target='remote',\n",
        "                    parent_run_id=parent_run_id,\n",
        "                    logger=logger\n",
        "                )\n",
        "                end = time.time()\n",
        "                print(\"time taken for transform {}\".format(end-start))\n",
        "                logger.info(\"time taken for transform {}\".format(end-start))\n",
        "                if sdk_has_validate_data_splits:\n",
        "                    try:\n",
        "                        logger.info(\"Validating data splits now.\")\n",
        "                        _validate_data_splits(X=transformed_data_context.X,\n",
        "                                              y=transformed_data_context.y,\n",
        "                                              X_valid=transformed_data_context.X_valid,\n",
        "                                              y_valid=transformed_data_context.y_valid,\n",
        "                                              cv_splits=transformed_data_context.cv_splits,\n",
        "                                              automl_settings=automl_settings_obj)\n",
        "                        data_splits_validated = True\n",
        "                    except Exception as data_split_exception:\n",
        "                        data_splits_validated = False\n",
        "                        logger.error(\"Meeting validation errors {}.\".format(data_split_exception))\n",
        "                        log_traceback(data_split_exception, logger)\n",
        "                        raise data_split_exception\n",
        "                logger.info(\"Start setting problem info.\")\n",
        "                automl.set_problem_info(transformed_data_context.X, transformed_data_context.y,\n",
        "                                        automl_settings_obj.task_type,\n",
        "                                        current_run=current_run,\n",
        "                                        preprocess=automl_settings_obj.preprocess,\n",
        "                                        lag_length=automl_settings_obj.lag_length,\n",
        "                                        transformed_data_context=transformed_data_context,\n",
        "                                        enable_cache=automl_settings_obj.enable_cache,\n",
        "                                        subsampling=enable_subsampling)\n",
        "            except Exception as e:\n",
        "                if sdk_has_validate_data_splits and not data_splits_validated:\n",
        "                    logger.error(\"sdk_has_validate_data_splits is True and data_splits_validated is False {}.\".format(e))\n",
        "                    log_traceback(e, logger)\n",
        "                    raise e\n",
        "                else:\n",
        "                    logger.warning(\"Setup failed, fall back to old model {}\".format(e))\n",
        "                    print(\"Setup failed, fall back to old model {}\".format(e))\n",
        "                    automl.set_problem_info(\n",
        "                        X=fit_iteration_parameters_dict.get('X'),\n",
        "                        y=fit_iteration_parameters_dict.get('y'),\n",
        "                        task_type=task_type, current_run=current_run,\n",
        "                        preprocess=preprocess, subsampling=enable_subsampling\n",
        "                    )\n",
        "        else:\n",
        "            logger.info(\"Start setting problem info using old model.\")\n",
        "            if sdk_has_validate_data_splits:\n",
        "                _validate_data_splits(X=fit_iteration_parameters_dict.get('X'),\n",
        "                                      y=fit_iteration_parameters_dict.get('y'),\n",
        "                                      X_valid=fit_iteration_parameters_dict.get('X_valid'),\n",
        "                                      y_valid=fit_iteration_parameters_dict.get('y_valid'),\n",
        "                                      cv_splits=fit_iteration_parameters_dict.get('cv_splits_indices'),\n",
        "                                      automl_settings=automl_settings_obj)\n",
        "            automl.set_problem_info(\n",
        "                X=fit_iteration_parameters_dict.get('X'),\n",
        "                y=fit_iteration_parameters_dict.get('y'),\n",
        "                task_type=task_type, current_run=current_run,\n",
        "                preprocess=preprocess, subsampling=enable_subsampling\n",
        "            )\n",
        "\n",
        "    def _post_setup(logger):\n",
        "        logger.info(\"Setup run completed successfully!\")\n",
        "        print(\"Setup run completed successfully!\")\n",
        "\n",
        "    def _get_automl_settings(automl_settings, logger):\n",
        "        automl_settings_obj = None\n",
        "        current_run = Run.get_submitted_run()\n",
        "        found_data_store = False\n",
        "        data_store = None\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        try:\n",
        "            experiment = current_run.experiment\n",
        "\n",
        "            parent_run_id = _get_parent_run_id(current_run._run_id)\n",
        "            print(\"parent run id {}\".format(parent_run_id))\n",
        "\n",
        "            automl_settings_obj = _AutoMLSettings.from_string_or_dict(automl_settings)\n",
        "            data_store = experiment.workspace.get_default_datastore()\n",
        "            found_data_store = True\n",
        "        except Exception as e:\n",
        "            logger.warning(\"getting data store, fallback to default {}\".format(e))\n",
        "            print(\"failed to get default data store  {}\".format(e))\n",
        "            found_data_store = False\n",
        "\n",
        "        end = time.time()\n",
        "        print(\"Caching supported {}, time taken for get default DS {}\".format(sdk_has_cache_capability and found_data_store, (end - start)))\n",
        "\n",
        "        return automl_settings_obj, found_data_store, data_store\n",
        "\n",
        "    def _load_transformed_data_context_from_cache(automl_settings_obj, parent_run_id,\n",
        "                                                 found_data_store, data_store,\n",
        "                                                 logger):\n",
        "        logger.info(\"Loading the data from datastore.\")\n",
        "        transformed_data_context = None\n",
        "        if sdk_has_cache_capability and automl_settings_obj is not None and automl_settings_obj.enable_cache and \\\n",
        "                automl_settings_obj.preprocess and found_data_store:\n",
        "\n",
        "            try:\n",
        "                start = time.time()\n",
        "                transformed_data_context = TransformedDataContext(X={},\n",
        "                                                                  run_id=parent_run_id,\n",
        "                                                                  run_targets='remote',\n",
        "                                                                  logger=logger,\n",
        "                                                                  enable_cache=True,\n",
        "                                                                  data_store=data_store)\n",
        "                transformed_data_context._load_from_cache()\n",
        "                end = time.time()\n",
        "                logger.info(\"Time taken for loading from cache {}.\".format(end-start))\n",
        "                print(\"Time taken for loading from cache {}.\".format(end-start))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(\"Error while loading from cache, defaulting to redo {}\".format(e))\n",
        "                transformed_data_context = None\n",
        "        return transformed_data_context\n",
        "\n",
        "    def _start_run(automl_settings_obj, run_id, training_percent, iteration,\n",
        "                  pipeline_spec, pipeline_id,\n",
        "                  dataprep_json, script_directory,\n",
        "                  entry_point,\n",
        "                  logger,\n",
        "                  transformed_data_context=None):\n",
        "        logger.info(\"Starting the run.\")\n",
        "        if transformed_data_context is None:\n",
        "            logger.info(\"transformed_data_context is None, loading data now.\")\n",
        "            fit_iteration_parameters_dict = _prepare_data(\n",
        "                dataprep_json=dataprep_json,\n",
        "                automl_settings_obj=automl_settings_obj,\n",
        "                script_directory=script_directory,\n",
        "                entry_point=entry_point,\n",
        "                logger=logger\n",
        "            )\n",
        "\n",
        "            fit_iteration_parameters_dict = _get_auto_cv_dict(fit_iteration_parameters_dict, automl_settings_obj, logger)\n",
        "\n",
        "            result = fit_pipeline(\n",
        "                pipeline_script=pipeline_spec,\n",
        "                automl_settings=automl_settings_obj,\n",
        "                run_id=run_id,\n",
        "                fit_iteration_parameters_dict = fit_iteration_parameters_dict,\n",
        "                train_frac=training_percent/100,\n",
        "                iteration=iteration,\n",
        "                pipeline_id=pipeline_id,\n",
        "                remote=True,\n",
        "                child_run_metrics=Run.get_context(_batch_upload_metrics=False),\n",
        "                logger=logger)\n",
        "        else:\n",
        "            if automl_settings_obj.n_cross_validations is None and transformed_data_context.X_valid is None:\n",
        "                automl_settings_obj.n_cross_validations = _get_cv_from_transformed_data_context(\n",
        "                    transformed_data_context, logger)\n",
        "            result = fit_pipeline(\n",
        "                pipeline_script=pipeline_spec,\n",
        "                automl_settings=automl_settings_obj,\n",
        "                run_id=run_id,\n",
        "                train_frac=training_percent/100,\n",
        "                iteration=iteration,\n",
        "                pipeline_id=pipeline_id,\n",
        "                remote=True,\n",
        "                child_run_metrics=Run.get_context(_batch_upload_metrics=False),\n",
        "                logger=logger,\n",
        "                transformed_data_context=transformed_data_context)\n",
        "        logger.info(\"Run finished.\")\n",
        "        return result\n",
        "\n",
        "    def _post_run(result, run_id, automl_settings, logger):\n",
        "        print(\"for Run Id : \", run_id)\n",
        "        print(\"result : \", result)\n",
        "        if len(result['errors']) > 0:\n",
        "            err_type = next(iter(result['errors']))\n",
        "            inner_ex = result['errors'][err_type]['exception']\n",
        "            inner_ex.error_type = ErrorTypes.Client\n",
        "            log_traceback(inner_ex, logger)\n",
        "            raise RuntimeError(inner_ex) from inner_ex\n",
        "\n",
        "        score = result[automl_settings['primary_metric']]\n",
        "        duration = result['fit_time']\n",
        "        print(\"Score : \", score)\n",
        "        print(\"Duration : \", duration)\n",
        "        print(\"Childrun completed successfully!\")\n",
        "        logger.info(\"Childrun completed successfully!\")\n",
        "\n",
        "    def driver_wrapper(\n",
        "        script_directory, automl_settings, run_id, training_percent,\n",
        "        iteration, pipeline_spec, pipeline_id, dataprep_json, entry_point,\n",
        "        **kwargs\n",
        "    ):\n",
        "        automl_settings_obj = _AutoMLSettings.from_string_or_dict(automl_settings)\n",
        "        logger, sdk_has_custom_dimension_logger = _init_logger(automl_settings_obj)\n",
        "        if sdk_has_custom_dimension_logger:\n",
        "            logger.update_default_properties({\n",
        "                \"parent_run_id\": _get_parent_run_id(run_id),\n",
        "                \"child_run_id\": run_id\n",
        "            })\n",
        "        logger.info(\"[RunId:{}]: remote automl driver begins.\".format(run_id))\n",
        "\n",
        "        try:\n",
        "            script_directory = _init_directory(directory=script_directory, logger=logger)\n",
        "\n",
        "            automl_settings_obj, found_data_store, data_store = _get_automl_settings(\n",
        "                automl_settings=automl_settings, logger=logger)\n",
        "\n",
        "            transformed_data_context = _load_transformed_data_context_from_cache(\n",
        "                automl_settings_obj=automl_settings_obj,\n",
        "                parent_run_id=_get_parent_run_id(run_id),\n",
        "                found_data_store=found_data_store,\n",
        "                data_store=data_store,\n",
        "                logger=logger\n",
        "            )\n",
        "            result = _start_run(automl_settings_obj=automl_settings_obj,\n",
        "                            run_id=run_id,\n",
        "                            training_percent=training_percent,\n",
        "                            iteration=iteration,\n",
        "                            pipeline_spec=pipeline_spec,\n",
        "                            pipeline_id=pipeline_id,\n",
        "                            dataprep_json=dataprep_json,\n",
        "                            script_directory=script_directory,\n",
        "                            entry_point=entry_point,\n",
        "                            logger=logger,\n",
        "                            transformed_data_context=transformed_data_context)\n",
        "            _post_run(result=result, run_id=run_id, automl_settings=automl_settings, logger=logger)\n",
        "        except Exception as e:\n",
        "            logger.error(\"driver_wrapper meets exceptions. {}\".format(e))\n",
        "            log_traceback(e, logger)\n",
        "            raise Exception(e)\n",
        "\n",
        "        logger.info(\"[RunId:{}]: remote automl driver finishes.\".format(run_id))\n",
        "        return result\n",
        "\n",
        "    def setup_wrapper(\n",
        "        script_directory, dataprep_json, entry_point, automl_settings, task_type,\n",
        "        preprocess, enable_subsampling, num_iterations,\n",
        "        **kwargs\n",
        "    ):\n",
        "        automl_settings_obj = _AutoMLSettings.from_string_or_dict(automl_settings)\n",
        "\n",
        "        logger, sdk_has_custom_dimension_logger = _init_logger(automl_settings_obj)\n",
        "        try:\n",
        "            child_run_id = Run.get_submitted_run()._run_id\n",
        "            parent_run_id = _get_parent_run_id(child_run_id)\n",
        "            if sdk_has_custom_dimension_logger:\n",
        "                logger.update_default_properties({\n",
        "                    \"parent_run_id\": parent_run_id,\n",
        "                    \"child_run_id\": child_run_id\n",
        "                })\n",
        "            logger.info(\"[ParentRunId:{}]: remote setup script begins.\".format(parent_run_id))\n",
        "            script_directory = _init_directory(directory=script_directory, logger=logger)\n",
        "\n",
        "            logger.info(\"Preparing data for set problem info now.\")\n",
        "\n",
        "            fit_iteration_parameters_dict = _prepare_data(\n",
        "                dataprep_json=dataprep_json,\n",
        "                automl_settings_obj=automl_settings_obj,\n",
        "                script_directory=script_directory,\n",
        "                entry_point=entry_point,\n",
        "                logger=logger\n",
        "            )\n",
        "            fit_iteration_parameters_dict = _get_auto_cv_dict(fit_iteration_parameters_dict, automl_settings_obj, logger)\n",
        "\n",
        "            print(\"Setting Problem Info now.\")\n",
        "            _set_problem_info_for_setup(\n",
        "                fit_iteration_parameters_dict=fit_iteration_parameters_dict,\n",
        "                automl_settings_obj=automl_settings_obj,\n",
        "                task_type=task_type,\n",
        "                preprocess=preprocess,\n",
        "                enable_subsampling=enable_subsampling,\n",
        "                num_iterations=num_iterations,\n",
        "                logger=logger)\n",
        "        except Exception as e:\n",
        "            logger.error(\"setup_wrapper meets exceptions. {}\".format(e))\n",
        "            log_traceback(e, logger)\n",
        "            raise Exception(e)\n",
        "\n",
        "        _post_setup(logger=logger)\n",
        "        logger.info(\"[ParentRunId:{}]: remote setup script finishes.\".format(parent_run_id))\n",
        "        return # PLACEHOLDER for RemoteScript helper functions\n",
        "\n",
        "args = sys.argv\n",
        "aml_token = None\n",
        "script_directory = None\n",
        "print(\"Starting the model test run....\")\n",
        "\n",
        "preprocess = \"True\"  # PLACEHOLDER\n",
        "run_id = \"bc5d68bc-d4d6-419c-895a-b251662cf29f\"  # PLACEHOLDER\n",
        "training_run_id = \"model_loan_validationset_21\" # PLACEHOLDER\n",
        "automl_settings = {'is_subgraph_orchestration':False,'is_automode':True,'path':'./sample_projects/','subscription_id':'84677e42-3672-4e5b-98f7-81f8a44649a9','resource_group':'ML_Project','workspace_name':'ML_ProjectWS1','compute_target':'cpu-cluster','iterations':1000,'primary_metric':'AUC_weighted','task_type':'classification','IsImageTask':False,'IsTextDNNTask':False,'validation_size':0.2,'test_size':0.2,'n_cross_validations':None,'preprocess':True,'is_timeseries':False,'time_column_name':None,'grain_column_names':None,'max_cores_per_iteration':-1,'max_concurrent_iterations':2,'max_nodes':1,'iteration_timeout_minutes':15,'enforce_time_on_windows':False,'experiment_timeout_minutes':15,'exit_score':'NaN','experiment_exit_score':'NaN','whitelist_models':None,'blacklist_models':['LogisticRegression','SGD','MultinomialNaiveBayes','BernoulliNaiveBayes','SVM','KNN','DecisionTree','ExtremeRandomTrees','RandomForest'],'blacklist_algos':['LogisticRegression','SGD','MultinomialNaiveBayes','BernoulliNaiveBayes','SVM','KNN','DecisionTree','ExtremeRandomTrees','RandomForest','TensorFlowLinearClassifier','TensorFlowDNN'],'auto_blacklist':False,'blacklist_samples_reached':False,'exclude_nan_labels':False,'verbosity':20,'model_explainability':True,'enable_onnx_compatible_models':False,'enable_feature_sweeping':False,'send_telemetry':True,'enable_early_stopping':True,'early_stopping_n_iters':20,'distributed_dnn_max_node_check':False,'enable_distributed_featurization':True,'enable_distributed_dnn_training':True,'enable_distributed_dnn_training_ort_ds':False,'ensemble_iterations':15,'enable_tf':False,'enable_cache':False,'enable_subsampling':False,'metric_operation':'maximize','enable_streaming':False,'use_incremental_learning_override':False,'force_streaming':False,'enable_dnn':False,'is_gpu_tmp':False,'enable_run_restructure':False,'featurization':'auto','vm_priority':'dedicated','label_column_name':'loan_status','weight_column_name':None,'miro_flight':'default','many_models':False,'many_models_process_count_per_node':0,'automl_many_models_scenario':None,'enable_batch_run':True,'save_mlflow':True,'track_child_runs':True,'test_include_predictions_only':False,'enable_mltable_quick_profile':'True','has_multiple_series':False,'_enable_future_regressors':False,'enable_ensembling':True,'enable_stack_ensembling':False,'ensemble_download_models_timeout_sec':300.0,'stack_meta_learner_train_percentage':0.2,'vm_type':'STANDARD_D2_V2','process_count_per_instance':0,'gpu_memory_gb':0.0} # PLACEHOLDER for AutoMLSettings\n",
        "dataprep_json = None  # PLACEHOLDER\n",
        "mltable_data_json = \"{\\\"Type\\\":\\\"MLTable\\\",\\\"TrainData\\\":{\\\"Uri\\\":\\\"azureml://locations/eastus/workspaces/7171f9b6-3d02-48f4-ac3a-50cd60c22aea/data/Loan_dataset/versions/1\\\",\\\"ResolvedUri\\\":\\\"azureml://locations/eastus/workspaces/7171f9b6-3d02-48f4-ac3a-50cd60c22aea/data/Loan_dataset/versions/1\\\",\\\"AssetId\\\":\\\"azureml://locations/eastus/workspaces/7171f9b6-3d02-48f4-ac3a-50cd60c22aea/data/Loan_dataset/versions/1\\\"},\\\"TestData\\\":null,\\\"ValidData\\\":null}\" # PLACEHOLDER\n",
        "entry_point = \"get_data.py\" # PLACEHOLDER\n",
        "\n",
        "print(\"run_id in the real script: \", run_id)\n",
        "project_dir = \"/tmp/azureml_runs/\" + run_id\n",
        "\n",
        "enable_streaming = False # PLACEHOLDER\n",
        "\n",
        "if enable_streaming is not None:\n",
        "    print(\"Set enable_streaming flag to\", enable_streaming)\n",
        "    automl_settings['enable_streaming']=enable_streaming\n",
        "\n",
        "test_include_predictions_only = False # PLACEHOLDER\n",
        "\n",
        "if test_include_predictions_only is not None:\n",
        "    print(\"Set test_include_predictions_only flag to\", test_include_predictions_only)\n",
        "    automl_settings['test_include_predictions_only'] = test_include_predictions_only\n",
        "\n",
        "def model_test_run():\n",
        "    global script_directory\n",
        "\n",
        "    model_test_wrapper(\n",
        "        script_directory=script_directory,\n",
        "        automl_settings=automl_settings,\n",
        "        run_id=run_id,\n",
        "        training_run_id=training_run_id,\n",
        "        dataprep_json=dataprep_json,\n",
        "        mltable_data_json=mltable_data_json,\n",
        "        entry_point=entry_point)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_test_run()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "index_order": 1,
    "automl_sdk_version": "1.56.0",
    "exclude_from_index": false,
    "task": "Submit a run on Azure Machine Learning Compute.",
    "deployment": [
      "None"
    ],
    "authors": [
      {
        "name": "vivijay"
      }
    ],
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "compute": [
      "AML Compute"
    ],
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "Diabetes"
    ],
    "category": "training",
    "framework": [
      "None"
    ],
    "friendly_name": "Train on Azure Machine Learning Compute",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}